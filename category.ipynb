{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "def data_preprocessing(dataset):\n",
    "    # Determine whether a column contains numerical or nominial values\n",
    "    # Create a new Pandas dataframe to maintain order of columns when doing One-Hot Coding on Nominial values\n",
    "    new_dataframe = pd.DataFrame()\n",
    "    # Iterate through all the columns of the training_set\n",
    "    for x in dataset.columns:\n",
    "        # Determine if the column 'x' in training set is a Nominial Data or Numerical\n",
    "        if is_string_dtype(dataset[x]) and not is_numeric_dtype(dataset[x]):\n",
    "            # Apply One-Hot Encoding onto Pandas Series at column 'x'\n",
    "            dummies = pd.get_dummies(dataset[x], prefix=x, prefix_sep='.', drop_first=True)\n",
    "            # Combine the One-Hot Encoding Dataframe to our new dataframe to the new_dataframe\n",
    "            new_dataframe = pd.concat([new_dataframe, dummies],axis=1)\n",
    "        else:\n",
    "            # If the column 'x' is a Numerical Data, then just add it to the new_dataframe\n",
    "            new_dataframe = pd.concat([new_dataframe, dataset[x]],axis=1)\n",
    "    return new_dataframe\n",
    "\n",
    "df = pd.read_csv(\"/Users/adaates/Desktop/code/hw4-trees-sondande/occupancy.csv\")\n",
    "\n",
    "# Get the target column\n",
    "label_col = df.iloc[:,:1]\n",
    "\n",
    "# Get the features\n",
    "features = df.iloc[:,1:]\n",
    "\n",
    "training_set_percent = 0.8\n",
    "testing_set_percent = 0.2\n",
    "\n",
    "randomSeed = 12345\n",
    "\n",
    "# Preprocess the dataset with one hot encoding\n",
    "cleaned_features = data_preprocessing(features)\n",
    "\n",
    "# Combine the target column with the features\n",
    "df = pd.concat([label_col, cleaned_features], axis=1)\n",
    "\n",
    "shuffled_df = df.sample(frac=1, random_state=randomSeed)\n",
    "\n",
    "print(f\"Number of Instances in Dataframe: {len(df)}\")\n",
    "\n",
    "splits_indices = [int(training_set_percent * len(df))]\n",
    "print(f\"Splits indexes they begin at: {splits_indices}\\n\")\n",
    "training_set, testing_set = np.split(shuffled_df, splits_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    total_row = train_data.shape[0]\n",
    "    total_entr = 0\n",
    "\n",
    "    for c in class_list:\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0]\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row)\n",
    "        total_entr += total_class_entr\n",
    "\n",
    "    return total_entr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "\n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n",
    "\n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count\n",
    "            entropy_class = - probability_class * np.log2(probability_class)\n",
    "\n",
    "        entropy += entropy_class\n",
    "\n",
    "    return entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique()\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "\n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list)\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy\n",
    "\n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    feature_list = train_data.columns.drop(label)\n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None\n",
    "\n",
    "    for feature in feature_list:\n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "        if max_info_gain < feature_info_gain:\n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature\n",
    "\n",
    "    return max_info_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False)\n",
    "    tree = {}\n",
    "\n",
    "    for feature_value, count in feature_value_count_dict.iteritems():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "\n",
    "        assigned_to_node = False\n",
    "        for c in class_list:\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n",
    "\n",
    "            if class_count == count:\n",
    "                tree[feature_value] = c\n",
    "                train_data = train_data[train_data[feature_name] != feature_value]\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node:\n",
    "            tree[feature_value] = \"?\"\n",
    "\n",
    "    return tree, train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0:\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list)\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list)\n",
    "        next_root = None\n",
    "\n",
    "        if prev_feature_value != None:\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else:\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "\n",
    "        for node, branch in list(next_root.items()):\n",
    "            if branch == \"?\":\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node]\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def id3(training_set, label):\n",
    "    train_data = training_set.copy()\n",
    "    tree = {}\n",
    "    class_list = train_data[label].unique()\n",
    "    make_tree(tree, None, train_data, label, class_list)\n",
    "\n",
    "    return tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    else:\n",
    "        root_node = next(iter(tree))\n",
    "        feature_value = instance[root_node]\n",
    "        if feature_value in tree[root_node]:\n",
    "            return predict(tree[root_node][feature_value], instance)\n",
    "        else:\n",
    "            return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def evaluate(tree, test_data_m, label):\n",
    "    correct_preditct = 0\n",
    "    wrong_preditct = 0\n",
    "    for index, row in test_data_m.iterrows():\n",
    "        result = predict(tree, test_data_m.iloc[index])\n",
    "        if result == test_data_m[label].iloc[index]:\n",
    "            correct_preditct += 1\n",
    "        else:\n",
    "            wrong_preditct += 1\n",
    "    accuracy = correct_preditct / (correct_preditct + wrong_preditct)\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tree = id3(training_set, 'label')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}